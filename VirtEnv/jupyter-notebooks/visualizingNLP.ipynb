{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a786870a-8a11-4b47-876b-6dc2fb75e696",
   "metadata": {},
   "source": [
    "# Court Record Code #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac769c8-f182-4baf-823b-5806ea480280",
   "metadata": {},
   "source": [
    "This imports all the software needed to run the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6302b6dd-91ad-4029-92fc-d367959f630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "import re as regex\n",
    "from saxonche import PySaxonProcessor\n",
    "from os import getcwd\n",
    "#Use this instead for windows:\n",
    "#w/ this: xq.set_query_base_uri(Path('.', 'foo.xml').absolute().as_uri())\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf72f7-8663-43d7-8472-818559738b26",
   "metadata": {},
   "source": [
    "This loads the Spacy model we'll use for NLP processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0812f5-12aa-4516-8e09-ec93a89678e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp = spacy.cli.download(\"en_core_web_lg\")\n",
    "#You will only need the above code once. Uncomment this to download the language model, and comment this line again the next time you run this code.\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba54f74-dcbb-4346-b88d-82a4f95f8d3e",
   "metadata": {},
   "source": [
    "This shows the input file path, which is the the corpus text files from Ace Attorney, and the output, which is a placeholder output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ef8e60-d199-489c-9dad-62701e96e006",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputPath = 'AAcorpus-xml'\n",
    "OutputPath = 'testOutput'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb60a0-db06-42e7-84c2-2fa09d543642",
   "metadata": {},
   "source": [
    "This reads the text files in the corpus and arranges data based on how many characters are in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54153a45-648b-4302-9f69-45f4c6912811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTextFiles(InputPath):\n",
    "    # This function uses XPath to read the XML input\n",
    "    for file in os.listdir(InputPath):\n",
    "        if file.endswith('.xml'):\n",
    "            filepath = f\"{InputPath}/{file}\"\n",
    "            with PySaxonProcessor(license=False) as proc:\n",
    "                xml = open(filepath, encoding='utf-8').read()\n",
    "                xp = proc.new_xpath_processor()\n",
    "                node = proc.parse_xml(xml_text=xml)\n",
    "                xp.set_context(xdm_item=node)\n",
    "                # xpath = xp.evaluate('//your/xpath/here')\n",
    "                xpath = xp.evaluate('//line/@who => distinct-values()')\n",
    "                count = xp.evaluate('//line/@who => distinct-values()')\n",
    "                string = str(xpath)\n",
    "                print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e96b9a3-0d33-44c5-825f-06f8f8fbee0b",
   "metadata": {},
   "source": [
    "This uses XPath to gather data in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca7c86-0af1-4d1e-b378-b391c71d2f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xqueryOverFiles(InputPath):\n",
    "    # This function uses XQuery to search with XPath over many files in one collection\n",
    "    with PySaxonProcessor(license=False) as proc:\n",
    "        print(proc.version)\n",
    "        xq = proc.new_xquery_processor()\n",
    "        xq.set_query_base_uri(Path('.', 'foo.xml').absolute().as_uri()) #For Windows machines\n",
    "        #XQuery comments are contained within (:  :)'s\n",
    "        xq.set_query_content('''\n",
    "        (: ebb: We're writing a query-based syntax called FLWOR (pronounced \"flower\") and every FLWOR requires a return statement at the end. :)\n",
    "let $AceAtt := collection('AAcorpus-xml/?select=*.xml')\n",
    "let $phoenixLines := $AceAtt//line[@speaker=\"Phoenix\" or @speaker=\"Wright\"]/text()\n",
    "for $pt in $phoenixLines\n",
    "    let $length := $pt ! string-length()\n",
    "    where $length gt 300\n",
    "        order by $length descending\n",
    "        return $pt\n",
    "''')\n",
    "        r = xq.run_query_to_value() # You can use r = xq.run_query_to_string(), but I think the output looks way worse.\n",
    "        #print(r)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c90b3-edab-4a3b-885d-7de1f1aaefea",
   "metadata": {},
   "source": [
    "This shows the output of XQuery input strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a3d1f-047f-4757-951a-7f350dde9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = str(xqueryOverFiles(InputPath))\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f0319-ccd8-449f-afbd-7ede78a53d8a",
   "metadata": {},
   "source": [
    "This shows Phoenix Wright's lines in all our chosen cases. It then sorts all the proper nouns he said and arranges the frequency of how often he said them, and how many proper nouns he said, and arranges them into a dictionary based on how many times and how often he said these words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f96a96-80d0-4585-8832-f1ebcd2d532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenixLines = nlp(output)\n",
    "phoenixLemmas = []\n",
    "for token in phoenixLines:\n",
    "    if token.pos_ == \"PROPN\":\n",
    "        lemma = token.lemma_\n",
    "        phoenixLemmas.append(lemma)\n",
    "\n",
    "# Counter() finds out how frequently each verb lemma shows up in the entire verb list.\n",
    "# Counter() removes duplicates and counts the number of times something appears.\n",
    "# And it outputs a dictionary of key:value pairs already sorted from highest to lowest count.\n",
    "\n",
    "lemmaFreq = Counter(phoenixLemmas)\n",
    "\n",
    "print(f\"Lemma frequency: \\n {lemmaFreq}\")\n",
    "\n",
    "# We can even calculate the percentage each verb is used.\n",
    "# The totalVerbCount will be the length of the BenderLemmas list.\n",
    "\n",
    "totalPropNounCount = len(phoenixLemmas)\n",
    "print(f'Total Proper Noun count: {totalPropNounCount}')\n",
    "#For these lines in particular, spacy mis-identifies several nouns as proper nouns. Several capitalized words from the starts of sentences appear in the list...\n",
    "\n",
    "mostCommon = dict(lemmaFreq.most_common()[:44])\n",
    "print(f\"Most common Lemmas: \\n{mostCommon}\")\n",
    "\n",
    "counts = list(mostCommon.values())\n",
    "lems = list(mostCommon.keys())\n",
    "print(counts)\n",
    "print(lems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ffa1b-6ed5-4486-96d3-7a676e02282f",
   "metadata": {},
   "source": [
    "This makes a chart based on all the proper nouns Phoenix has said in all our chosen Ace Attorney cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d3c21-a2a9-431e-9206-f5c27e9b1dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I removed the code specifically for the Jupyter Notebook, everything seems to be working fine!\n",
    "# Set figure size configuration\n",
    "plt.figure(figsize=(20,20))\n",
    "# Create bar plot using seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(x=counts, y=lems, palette=sns.color_palette(\"husl\", len(counts)), legend=False)\n",
    "#I chose a pretty color group for the graph, though I admit it's not that good since it's circular...\n",
    "# Adding labels and title\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Proper Nouns')\n",
    "plt.title('Most Common Proper Nouns from Phoenix Wright')\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "#rcc: I got this error when making the graph, you may get something similar:\n",
    "#C:\\Users\\Reece\\OneDrive\\Desktop\\GitHub\\DIGIT210\\VirtEnv\\XPath-XQuery\\VisualizingNLP.py:102: FutureWarning:\n",
    "#Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
    "#  sns.barplot(x=counts, y=lems, palette=sns.color_palette(\"husl\", len(counts)), legend=False)\n",
    "#I tried to mess with my code to fix it, but nothing got rid of the error, so I'm still\n",
    "#not sure what it means"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
